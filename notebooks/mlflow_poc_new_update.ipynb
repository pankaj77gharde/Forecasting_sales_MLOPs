{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc15908",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# pre processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e470dd6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:47:10.004567Z",
     "start_time": "2023-02-27T15:47:09.551181Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"In pre process first grouping by items i.e. 50 then by\n",
    "droping unique columns geting final X and Y dataframe\n",
    "for current data no need of null or nan value handling\n",
    "but we can add fun to deal with that in case data change\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def pre_pros(raw_df):\n",
    "    \"\"\"By using group by working on one item at a time\"\"\"\n",
    "    y = {}\n",
    "    X = {}\n",
    "    for item, data in raw_df.groupby(\"item\"):\n",
    "        item_data = data.drop(\n",
    "            [col for col in data.columns if data[col].nunique() == 1], axis=1\n",
    "        )\n",
    "        item_data.rename(columns={\"sales\": f\"sales_{item}\"}, inplace=True)\n",
    "        X.update({\"date\": item_data[\"date\"].values})\n",
    "        y.update({f\"sales_{item}\": item_data[f\"sales_{item}\"].values})\n",
    "    df_X = pd.DataFrame(X)\n",
    "    df_y = pd.DataFrame(y)\n",
    "    df_final = pd.concat([df_X, df_y], axis=1)\n",
    "    df_final[\"date\"] = pd.to_datetime(df_final[\"date\"], format=\"%Y-%m-%d\")\n",
    "    df_final = df_final.resample(\"D\", on=\"date\").sum()\n",
    "    df_final = df_final.reset_index()\n",
    "    \n",
    "    if not os.path.exists(\n",
    "        r\"D:\\MLOPs POC\\python_files\\prepros_sales_data\\updated_sales_data.csv\"\n",
    "    ):\n",
    "        os.mkdir(\"D:\\MLOPs POC\\python_files\\prepros_sales_data\")\n",
    "        df_final.to_csv(\n",
    "            r\"D:\\MLOPs POC\\python_files\\prepros_sales_data\\updated_sales_data.csv\",\n",
    "            index=False,\n",
    "        )\n",
    "        eval_model_train(df_final, [SARIMAX, Prophet], split_test=0.2)\n",
    "    else:\n",
    "        df_old = pd.read_csv(\n",
    "            r\"D:\\MLOPs POC\\python_files\\prepros_sales_data\\updated_sales_data.csv\"\n",
    "        )\n",
    "        df_new = df_final\n",
    "        df_final = pd.concat([df_old, df_new], axis=0, ignore_index=True)\n",
    "        df_final.to_csv(\n",
    "            r\"D:\\MLOPs POC\\python_files\\prepros_sales_data\\updated_sales_data.csv\",\n",
    "            index=False,\n",
    "        )\n",
    "        \n",
    "        eval_model_train(df_final, [SARIMAX, Prophet], split_test=0.2) \n",
    "        \n",
    "        return df_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b288a99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:47:10.019766Z",
     "start_time": "2023-02-27T15:47:10.004567Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# raw_df = r\"D:\\MLOPs POC\\python_files\\samp_data\\data_2013_to_2016.csv\"\n",
    "# raw_df = pd.read_csv(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd278e4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:47:10.034063Z",
     "start_time": "2023-02-27T15:47:10.019766Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pre_pros(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d0d18",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a33fa97",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# model eval on split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b1c4a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:47:11.895930Z",
     "start_time": "2023-02-27T15:47:10.034063Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Product wise Profet model is build and check its performance by using MAPE metrics.\n",
    "Store all the model and metrics data with the help of mlflow\"\"\"\n",
    "import sys\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from datetime import datetime\n",
    "\n",
    "# sys.path.insert(0, \"./Model\")\n",
    "# from model_eval import (\n",
    "#     eval_item_metrics,\n",
    "# )  # variable where all the MAPE values availble wrt each item  # d\n",
    "\n",
    "\n",
    "def train_final_model(data, dict_mod_met):  \n",
    "    \"\"\"considering whole data for traning final models\"\"\"\n",
    "    # date time formate\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"], format=\"%Y-%m-%d\")\n",
    "    data = data.sort_values(\"date\")\n",
    "    final_model_dict = {}\n",
    "    col_name = list(data.columns)\n",
    "    col_name.remove('date')\n",
    "    \n",
    "    date_now = datetime.now().date()\n",
    "    str_date_now = date_now.strftime(\"%Y_%m_%d\")\n",
    "    \n",
    "    for prod_name in col_name:\n",
    "    # work on algo one by one\n",
    "        mod_name = dict_mod_met[prod_name][\"best_model\"]\n",
    "        if mod_name == \"Prophet\":\n",
    "            with mlflow.start_run(run_name=f\"{prod_name}_run\") as _:\n",
    "                # train data processing as pere NP formate\n",
    "                data_prod = data.loc[:, [\"date\", prod_name]]\n",
    "                data_prod.columns = [\"ds\", \"y\"]\n",
    "\n",
    "                # model traning\n",
    "                mod = Prophet()\n",
    "                mod.fit(data_prod)\n",
    "                final_model_dict[prod_name] = mod\n",
    "                # mlflow tracking metrics and model item wise i.e. 50\n",
    "                mlflow.prophet.log_model(\n",
    "                    mod, f\"{prod_name}_model\"\n",
    "                )  # model train on whole data\n",
    "                # using eval_model performance metrics as per item\n",
    "                dict_eval = dict_mod_met[prod_name]\n",
    "                mlflow.log_metric(f\"MAPE_train\", dict_eval[\"MAPE_train\"])\n",
    "                mlflow.log_metric(f\"MAPE_test\", dict_eval[\"MAPE_test\"])\n",
    "                \n",
    "        elif mod_name == \"SARIMAX\" :\n",
    "            with mlflow.start_run(run_name=f\"{prod_name}_run\") as _:\n",
    "                # train data processing as pere NP formate\n",
    "                data_prod = data.loc[:, [\"date\", prod_name]]\n",
    "                data_prod.set_index(\"date\", inplace=True)\n",
    "\n",
    "                # model traning\n",
    "                mod = SARIMAX(data_prod, order=(1, 1, 1)) #, seasonal_order=(1, 1, 1, 7))\n",
    "                result = mod.fit()                \n",
    "                final_model_dict[prod_name] = result\n",
    "                # mlflow tracking metrics and model item wise i.e. 50\n",
    "                mlflow.statsmodels.log_model(\n",
    "                    result, f\"{prod_name}_model\"\n",
    "                )  # model train on whole data\n",
    "                # using eval_model performance metrics as per item\n",
    "                dict_eval = dict_mod_met[prod_name]\n",
    "                mlflow.log_metric(f\"MAPE_train\", dict_eval[\"MAPE_train\"])\n",
    "                mlflow.log_metric(f\"MAPE_test\", dict_eval[\"MAPE_test\"])\n",
    "\n",
    "    return final_model_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f1bb2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:47:12.327786Z",
     "start_time": "2023-02-27T15:47:11.895930Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Performance analysis of model by using evaluation metrics i.e. MAPE\n",
    "by building profet model for each item i.e. 50 models\"\"\"\n",
    "import pandas as pd\n",
    "from pmdarima.model_selection import train_test_split\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "eval_item_metrics = {}\n",
    "\n",
    "\n",
    "def eval_model(train_true, train_pred, test_true, test_pred):\n",
    "    \"\"\"MAPE metrics\"\"\"\n",
    "    mape_train = mean_absolute_percentage_error(train_true, train_pred)\n",
    "    mape_test = mean_absolute_percentage_error(test_true, test_pred)\n",
    "    dict_eval = {\"MAPE_train\": mape_train, \"MAPE_test\": mape_test}\n",
    "    return dict_eval\n",
    "\n",
    "\n",
    "def train_test_data(data, split_test):\n",
    "    \"\"\"Train test split\"\"\"\n",
    "    train, test = train_test_split(data, test_size=split_test)  # splite by dates\n",
    "    return {\"train\": train, \"test\": test}\n",
    "\n",
    "\n",
    "def eval_model_train(data_upd, list_algo, split_test=0.2):\n",
    "    data = data_upd.copy()\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"], format=\"%Y-%m-%d\")\n",
    "    data = data.sort_values(\"date\")\n",
    "    \"\"\"Using only train and test data\"\"\"\n",
    "    data_dic = train_test_data(data, split_test)\n",
    "    train = data_dic[\"train\"]\n",
    "    test = data_dic[\"test\"]\n",
    "    # convert to date time formate\n",
    "#     train[\"date\"] = pd.to_datetime(train[\"date\"], format=\"%Y-%m-%d\")\n",
    "#     test[\"date\"] = pd.to_datetime(test[\"date\"], format=\"%Y-%m-%d\")\n",
    "    model_dict = {}\n",
    "    col_names = train.columns\n",
    "    # work on algo one by one\n",
    "    for algo in list_algo:\n",
    "        if algo == Prophet:\n",
    "            algo_dict = {}\n",
    "            mod_name = \"Prophet\"\n",
    "            # work on profet part\n",
    "            for y_indx in range(1, len(train.columns)):\n",
    "                # item key for model_dict\n",
    "                item_name = col_names[y_indx]\n",
    "\n",
    "                # train data processing as pere NP formate\n",
    "                tsdf_train = train.iloc[:, [0, y_indx]]\n",
    "                tsdf_train.columns = [\"ds\", \"y\"]\n",
    "\n",
    "                # test data processing as pere NP formate\n",
    "                tsdf_test = test.iloc[:, [0, y_indx]]\n",
    "                tsdf_test.columns = [\"ds\", \"y\"]\n",
    "\n",
    "                # model traning\n",
    "                mod = Prophet()\n",
    "                mod.fit(tsdf_train)\n",
    "                model_dict[item_name] = mod\n",
    "\n",
    "                # train and test pred and true values\n",
    "                pred_train = mod.predict(tsdf_train)\n",
    "                pred_test = mod.predict(tsdf_test)\n",
    "                train_true = pred_train.iloc[:, 1]\n",
    "                train_pred = pred_train.iloc[:, 2]\n",
    "                test_true = pred_test.iloc[:, 1]\n",
    "                test_pred = pred_test.iloc[:, 2]\n",
    "\n",
    "                # model evaluation metrics\n",
    "                dict_eval = eval_model(train_true, train_pred, test_true, test_pred)\n",
    "                algo_dict[item_name] = dict_eval\n",
    "#                 eval_item_metrics[f\"{mod_name}_{item_name}\"] = dict_eval\n",
    "            \n",
    "        elif algo == SARIMAX:\n",
    "            mod_name = \"SARIMAX\"\n",
    "            algo_dict = {}\n",
    "            # work on auto arima part\n",
    "            for y_indx in range(1, len(train.columns)):\n",
    "                # item key for model_dict\n",
    "                item_name = col_names[y_indx]\n",
    "\n",
    "                tsdf_train = train.iloc[:, [0, y_indx]]\n",
    "                tsdf_train.set_index(\"date\", inplace=True)\n",
    "                tsdf_test = test.iloc[:, [0, y_indx]]\n",
    "                tsdf_test.set_index(\"date\", inplace=True)\n",
    "\n",
    "                # model traning\n",
    "                mod = SARIMAX(tsdf_train, order=(1, 1, 1))#, seasonal_order=(1, 1, 1, 7))\n",
    "                result = mod.fit()\n",
    "                model_dict[item_name] = result\n",
    "\n",
    "                # train and test pred and true values\n",
    "                pred_train = result.predict(start=tsdf_train.index[0], end=tsdf_train.index[-1])\n",
    "                pred_test = result.predict(start=tsdf_test.index[0], end=tsdf_test.index[-1])\n",
    "                train_true = tsdf_train\n",
    "                train_pred = pred_train\n",
    "                test_true = tsdf_test\n",
    "                test_pred = pred_test\n",
    "\n",
    "                # model evaluation metrics\n",
    "                dict_eval = eval_model(train_true, train_pred, test_true, test_pred)\n",
    "                algo_dict[item_name] = dict_eval\n",
    "#                 eval_item_metrics[f\"{mod_name}_{item_name}\"] = dict_eval\n",
    "        eval_item_metrics[mod_name] = algo_dict\n",
    "    # best model selection from yrained models \n",
    "    lis_df = []\n",
    "    for model in  eval_item_metrics.keys():\n",
    "        df_met = pd.DataFrame(eval_item_metrics[model]).loc[[\"MAPE_test\"], :]\n",
    "        df_met.index = [model]\n",
    "        lis_df.append(df_met)\n",
    "    conct_met_df = pd.concat(lis_df, axis=0)\n",
    "    dict_best_mod = {}\n",
    "    mode_names_indx = list(conct_met_df.index)\n",
    "    for prod in conct_met_df.columns:\n",
    "        index = conct_met_df[prod].argmin()\n",
    "        mod_dict = {\"best_model\" : mode_names_indx[index]}\n",
    "        mod_dict.update(eval_item_metrics[mode_names_indx[index]][prod]) \n",
    "        dict_best_mod[prod] = mod_dict\n",
    "        \n",
    "    # final model devlopment and storing with mlflow\n",
    "    final_best_mod = train_final_model(data_upd, dict_best_mod)\n",
    "    \n",
    "    return final_best_mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe467828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:47:12.343834Z",
     "start_time": "2023-02-27T15:47:12.329572Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data = r\"D:\\MLOPs POC\\python_files\\prepros_sales_data\\updated_sales_data.csv\"\n",
    "# data = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a7ea9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:47:12.351125Z",
     "start_time": "2023-02-27T15:47:12.344953Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# eval_model_train(data, [SARIMAX, Prophet], split_test=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770352e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T10:46:29.799983Z",
     "start_time": "2023-02-27T10:46:29.789668Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a19aa26d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T11:50:09.721718Z",
     "start_time": "2023-02-27T11:47:16.343126Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# model selection ... compare with last best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01483231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:47:12.366478Z",
     "start_time": "2023-02-27T15:47:12.351125Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Fetch the best model wrt each product by using metrics i.e. MAPE from mlflow track data\"\"\"\n",
    "import mlflow\n",
    "\n",
    "\n",
    "def best_model():\n",
    "    \"\"\"# path of mlflow folder\"\"\"\n",
    "    list_run = mlflow.search_runs()\n",
    "    run_name_list = set(list_run[\"tags.mlflow.runName\"])\n",
    "    best_model_runs = {}\n",
    "    for run_name in run_name_list:\n",
    "        df_item = list_run[list_run[\"tags.mlflow.runName\"] == run_name]\n",
    "        df_item = df_item.reset_index()\n",
    "        df_item = df_item.iloc[:, 1:]\n",
    "        df_item = df_item.sort_values(\"metrics.MAPE_test\")\n",
    "        best_model_runs[run_name] = df_item.loc[0][\"run_id\"]\n",
    "    #  delete rest of run id in future\n",
    "\n",
    "    return best_model_runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "269d3268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:47:12.383490Z",
     "start_time": "2023-02-27T15:47:12.367597Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mlflow.search_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "504950db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:47:12.399073Z",
     "start_time": "2023-02-27T15:47:12.383490Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run_model_dict= best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa409d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# forecasting with selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd836e6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:47:12.415851Z",
     "start_time": "2023-02-27T15:47:12.400350Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"First forecasting dataframe is created as per input argument provided then\n",
    "by using mlflow profet flavor fetching model and return forecasted data in\n",
    "standard dataframe formate\"\"\"\n",
    "from datetime import timedelta, datetime\n",
    "import calendar\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "\n",
    "\n",
    "def forecast_with_run_model(run_model_dict, latest_proc_data, next_month_count):\n",
    "    \"\"\"create dataframe for next month forecasting with current data used for traning model\"\"\"\n",
    "    try:\n",
    "        latest_proc_data[\"date\"] = pd.to_datetime(latest_proc_data[\"date\"])\n",
    "    finally:\n",
    "        year = list(latest_proc_data[\"date\"])[-1].year\n",
    "        month = list(latest_proc_data[\"date\"])[-1].month\n",
    "\n",
    "        list_mon_yr = []\n",
    "        for _ in range(1, next_month_count + 1):\n",
    "            new_month = month + 1\n",
    "            if new_month > 12:\n",
    "                month = 1\n",
    "                year += 1\n",
    "            else:\n",
    "                month = new_month\n",
    "            day_count = calendar.monthrange(year, month)[1]\n",
    "            list_mon_yr.append([month, year, day_count])\n",
    "\n",
    "        final_day_count = 0\n",
    "        for val in list_mon_yr:\n",
    "            final_day_count += val[-1]\n",
    "\n",
    "        start_ = datetime(list_mon_yr[0][1], list_mon_yr[0][0], 1)\n",
    "        end_ = start_ + timedelta(final_day_count - 1)\n",
    "\n",
    "        data_next_month = pd.date_range(start=start_, end=end_, freq=\"D\")\n",
    "        data_next_month = pd.DataFrame({\"ds\": data_next_month})\n",
    "\n",
    "        # fetch each best model from dict and forecast\n",
    "        dict_forecast = {}\n",
    "        for name, run_id in run_model_dict.items():\n",
    "            model_folder_name = f\"{name[:-3]}model\"\n",
    "            pyfunc_uri = f\"runs:/{run_id}/{model_folder_name}\"\n",
    "            pyfunc_model = mlflow.pyfunc.load_model(\n",
    "                pyfunc_uri\n",
    "            )  # we are using  flavor from mlflow\n",
    "            flavor = [i.split(\":\")[1].strip() for i in str(pyfunc_model).split(\"\\n\") if i.strip().startswith(\"flavor\")]\n",
    "            if flavor[0] == 'mlflow.statsmodels':\n",
    "                pred_df = pyfunc_model.predict(pd.DataFrame({\"start\": data_next_month.iloc[0,:] , \"end\":data_next_month.iloc[-1,:]})) ### sarima and profet same ????\n",
    "                col_val = pred_df.values\n",
    "            elif flavor[0] == 'mlflow.prophet':\n",
    "                pred_df = pyfunc_model.predict(data_next_month)\n",
    "                col_val = pred_df[\"yhat\"].values\n",
    "                \n",
    "            # final single datafarem with each item sales for next month\n",
    "            name_col = name[:-4]\n",
    "            dict_forecast[name_col] = col_val\n",
    "            df_fourcast = pd.DataFrame(dict_forecast)\n",
    "            final_forecast = pd.concat([data_next_month[\"ds\"], df_fourcast], axis=1)\n",
    "            final_forecast.rename(columns={\"ds\": \"date\"}, inplace=True)\n",
    "\n",
    "        # make dataframe in standered formate\n",
    "        col_name_order = [\"date\"]\n",
    "        col_name_order.extend([f\"sales_{i}\" for i in range(1, 51)])\n",
    "        final_forecast = final_forecast.reindex(col_name_order, axis=1)\n",
    "        final_forecast = final_forecast.round()\n",
    "        final_forecast.columns = [\"date\"] + [\n",
    "            f\"sales_{i}_forecast\" for i in range(1, 51)\n",
    "        ]\n",
    "    return final_forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d124013b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:47:12.433425Z",
     "start_time": "2023-02-27T15:47:12.417883Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# forecast_with_run_model(run_model_dict, data, 1) # profet working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e00459d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:47:12.448997Z",
     "start_time": "2023-02-27T15:47:12.433662Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# forecast_with_run_model(run_model_dict, data, 1) # sarimax working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a4031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T14:15:11.488670Z",
     "start_time": "2023-02-27T14:15:11.469029Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feaad817",
   "metadata": {},
   "source": [
    "# final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38e8c9e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:47:12.466750Z",
     "start_time": "2023-02-27T15:47:12.450820Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"It provides input from user and follow pipe line flow for loading input files,\n",
    "data processing, stornig process updated data, model building, best model selection\n",
    "and forecasting with api link\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import matplotlib\n",
    "\n",
    "# matplotlib.use(\"Agg\")\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# from flask import Flask, render_template, request\n",
    "\n",
    "# sys.path.insert(0, \"./Model_selection\")\n",
    "# from model_selection import best_model\n",
    "\n",
    "# sys.path.insert(0, \"./Forecasting\")\n",
    "# from forecasting import forecast_with_run_model\n",
    "\n",
    "# sys.path.insert(0, \"./Preprocess\")\n",
    "# from preprocess import pre_pros\n",
    "\n",
    "# app = Flask(\n",
    "#     __name__, static_folder=\"\"\n",
    "# )  # , static_folder=r\"D:\\MLOPs POC\\python_files\\static\"\n",
    "# pick_folder = r\"D:\\MLOPs POC\\python_files\\static\\forecast.png\"\n",
    "# # app.config[\"UPLODE_FOLDER\"] = pick_folder\n",
    "\n",
    "\n",
    "# @app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def forecast_data():\n",
    "    \"\"\"check the presence of new data if it presesnt then update current data..\n",
    "    if not then use the current data\"\"\"\n",
    "    path_ = r\"D:\\MLOPs POC\\python_files\\prepros_sales_data\\updated_sales_data.csv\"\n",
    "    # pick_store = os.path.join(app.config[\"UPLODE_FOLDER\"], \"forecast.svg\")\n",
    "\n",
    "#     if request.method == \"POST\":\n",
    "    if os.path.exists(path_):\n",
    "        data_df = pd.read_csv(rf\"{path_}\").iloc[-3:, :]\n",
    "    else:\n",
    "        raw_df_path = r\"D:\\MLOPs POC\\python_files\\samp_data\\data_2013_to_2016.csv\"\n",
    "        raw_df = pd.read_csv(raw_df_path)\n",
    "        pre_pros(raw_df)\n",
    "        data_df = pd.read_csv(rf\"{path_}\").iloc[-3:, :]\n",
    "        data_df = data_df.iloc[-3:, :]\n",
    "    # need to mension location of new data\n",
    "    new_path = r\"D:\\MLOPs POC\\python_files\\samp_data\\test\\next_month_data.csv\"\n",
    "    if os.path.exists(new_path):\n",
    "        new_path_df = pd.read_csv(new_path)\n",
    "        if new_path_df.iloc[-1,0] != data_df.iloc[-1,0]:\n",
    "            pre_pros(new_path_df)\n",
    "            data_df = pd.read_csv(rf\"{path_}\").iloc[-3:, :]\n",
    "            data_df = data_df.iloc[-3:, :]\n",
    "#             eval_model_train(data_df, [SARIMAX, Prophet], split_test=0.2)\n",
    "            \n",
    "    # gey proc data last date by using updated file\n",
    "#     month_count = request.form.get(\"month_count\")\n",
    "#     prod_name = request.form.get(\"product_name\")\n",
    "    month_count = 1 #int(month_count)\n",
    "    run_model_dict = best_model()\n",
    "    forecasted_month = forecast_with_run_model(\n",
    "        run_model_dict, data_df, month_count\n",
    "    )#[[\"date\", \"sales_1\"]]\n",
    "\n",
    "#         # Create a line plot of the output data\n",
    "#         plot_df = forecasted_month.set_index(\"date\")\n",
    "#         plt.figure(figsize=(15, 10), dpi=80)\n",
    "#         plt.plot(plot_df)\n",
    "#         plt.xlabel(\"Month\")\n",
    "#         plt.ylabel(\"Output\")\n",
    "#         plt.xticks(rotation=45)\n",
    "#         plt.savefig(pick_folder)\n",
    "#         plt.clf()\n",
    "#     else:\n",
    "#         forecasted_month = pd.DataFrame()\n",
    "\n",
    "    \"\"\"Need to add code for geting product wise result\"\"\"\n",
    "    return forecasted_month\n",
    "\n",
    "#     return render_template(\n",
    "#         \"index.html\",\n",
    "#         forecast=forecasted_month,\n",
    "#         # plot_graph=pick_store,\n",
    "#     )\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9db15b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T15:48:37.091206Z",
     "start_time": "2023-02-27T15:47:12.467361Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "21:17:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:17:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:17:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:17:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2023/02/27 21:18:02 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "21:18:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "21:18:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:18:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:18:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:18:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n",
      "C:\\Users\\pankaj.gharde\\Anaconda3\\lib\\site-packages\\prophet\\serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales_1_forecast</th>\n",
       "      <th>sales_2_forecast</th>\n",
       "      <th>sales_3_forecast</th>\n",
       "      <th>sales_4_forecast</th>\n",
       "      <th>sales_5_forecast</th>\n",
       "      <th>sales_6_forecast</th>\n",
       "      <th>sales_7_forecast</th>\n",
       "      <th>sales_8_forecast</th>\n",
       "      <th>sales_9_forecast</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_41_forecast</th>\n",
       "      <th>sales_42_forecast</th>\n",
       "      <th>sales_43_forecast</th>\n",
       "      <th>sales_44_forecast</th>\n",
       "      <th>sales_45_forecast</th>\n",
       "      <th>sales_46_forecast</th>\n",
       "      <th>sales_47_forecast</th>\n",
       "      <th>sales_48_forecast</th>\n",
       "      <th>sales_49_forecast</th>\n",
       "      <th>sales_50_forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>21.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>16.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>16.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>17.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>19.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>20.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>21.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>16.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>16.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>16.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-01-13</td>\n",
       "      <td>18.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>20.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>21.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-01-17</td>\n",
       "      <td>15.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-01-18</td>\n",
       "      <td>16.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>16.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>18.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>20.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>21.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>16.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>16.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>17.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>19.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>20.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>21.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>16.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows  51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sales_1_forecast  sales_2_forecast  sales_3_forecast  \\\n",
       "0  2017-01-01              21.0              57.0              34.0   \n",
       "1  2017-01-02              13.0              36.0              21.0   \n",
       "2  2017-01-03              16.0              43.0              25.0   \n",
       "3  2017-01-04              16.0              43.0              25.0   \n",
       "4  2017-01-05              17.0              46.0              28.0   \n",
       "5  2017-01-06              19.0              50.0              30.0   \n",
       "6  2017-01-07              20.0              53.0              32.0   \n",
       "7  2017-01-08              21.0              57.0              35.0   \n",
       "8  2017-01-09              13.0              36.0              22.0   \n",
       "9  2017-01-10              16.0              43.0              26.0   \n",
       "10 2017-01-11              16.0              43.0              26.0   \n",
       "11 2017-01-12              16.0              46.0              28.0   \n",
       "12 2017-01-13              18.0              49.0              30.0   \n",
       "13 2017-01-14              20.0              53.0              32.0   \n",
       "14 2017-01-15              21.0              56.0              35.0   \n",
       "15 2017-01-16              13.0              36.0              22.0   \n",
       "16 2017-01-17              15.0              43.0              26.0   \n",
       "17 2017-01-18              16.0              43.0              26.0   \n",
       "18 2017-01-19              16.0              46.0              28.0   \n",
       "19 2017-01-20              18.0              49.0              30.0   \n",
       "20 2017-01-21              20.0              53.0              32.0   \n",
       "21 2017-01-22              21.0              57.0              35.0   \n",
       "22 2017-01-23              13.0              36.0              22.0   \n",
       "23 2017-01-24              16.0              43.0              26.0   \n",
       "24 2017-01-25              16.0              44.0              26.0   \n",
       "25 2017-01-26              17.0              47.0              28.0   \n",
       "26 2017-01-27              19.0              50.0              31.0   \n",
       "27 2017-01-28              20.0              54.0              33.0   \n",
       "28 2017-01-29              21.0              58.0              35.0   \n",
       "29 2017-01-30              14.0              37.0              23.0   \n",
       "30 2017-01-31              16.0              44.0              26.0   \n",
       "\n",
       "    sales_4_forecast  sales_5_forecast  sales_6_forecast  sales_7_forecast  \\\n",
       "0               21.0              17.0              57.0              53.0   \n",
       "1               13.0              11.0              36.0              32.0   \n",
       "2               16.0              13.0              44.0              39.0   \n",
       "3               16.0              13.0              44.0              39.0   \n",
       "4               18.0              15.0              46.0              43.0   \n",
       "5               18.0              15.0              50.0              46.0   \n",
       "6               20.0              16.0              54.0              51.0   \n",
       "7               21.0              17.0              57.0              53.0   \n",
       "8               13.0              11.0              36.0              32.0   \n",
       "9               16.0              13.0              43.0              39.0   \n",
       "10              16.0              14.0              44.0              39.0   \n",
       "11              17.0              15.0              46.0              44.0   \n",
       "12              18.0              16.0              50.0              46.0   \n",
       "13              19.0              16.0              53.0              51.0   \n",
       "14              20.0              18.0              56.0              54.0   \n",
       "15              12.0              11.0              36.0              33.0   \n",
       "16              15.0              14.0              43.0              40.0   \n",
       "17              15.0              14.0              43.0              40.0   \n",
       "18              17.0              16.0              45.0              45.0   \n",
       "19              17.0              16.0              50.0              48.0   \n",
       "20              19.0              17.0              53.0              53.0   \n",
       "21              20.0              18.0              56.0              55.0   \n",
       "22              12.0              12.0              36.0              34.0   \n",
       "23              15.0              14.0              43.0              41.0   \n",
       "24              15.0              14.0              44.0              42.0   \n",
       "25              17.0              16.0              46.0              46.0   \n",
       "26              18.0              16.0              51.0              49.0   \n",
       "27              19.0              17.0              54.0              54.0   \n",
       "28              21.0              18.0              58.0              56.0   \n",
       "29              13.0              12.0              37.0              35.0   \n",
       "30              16.0              14.0              45.0              42.0   \n",
       "\n",
       "    sales_8_forecast  sales_9_forecast  ...  sales_41_forecast  \\\n",
       "0               74.0              46.0  ...               21.0   \n",
       "1               46.0              29.0  ...               14.0   \n",
       "2               56.0              35.0  ...               16.0   \n",
       "3               56.0              35.0  ...               16.0   \n",
       "4               60.0              39.0  ...               17.0   \n",
       "5               64.0              41.0  ...               19.0   \n",
       "6               69.0              44.0  ...               20.0   \n",
       "7               74.0              47.0  ...               20.0   \n",
       "8               46.0              29.0  ...               12.0   \n",
       "9               56.0              35.0  ...               15.0   \n",
       "10              56.0              36.0  ...               15.0   \n",
       "11              59.0              39.0  ...               16.0   \n",
       "12              64.0              41.0  ...               17.0   \n",
       "13              69.0              45.0  ...               19.0   \n",
       "14              73.0              48.0  ...               19.0   \n",
       "15              46.0              30.0  ...               11.0   \n",
       "16              56.0              36.0  ...               14.0   \n",
       "17              55.0              37.0  ...               14.0   \n",
       "18              59.0              40.0  ...               15.0   \n",
       "19              64.0              42.0  ...               17.0   \n",
       "20              69.0              46.0  ...               19.0   \n",
       "21              73.0              49.0  ...               19.0   \n",
       "22              46.0              31.0  ...               12.0   \n",
       "23              56.0              37.0  ...               15.0   \n",
       "24              56.0              38.0  ...               15.0   \n",
       "25              59.0              42.0  ...               16.0   \n",
       "26              64.0              44.0  ...               18.0   \n",
       "27              69.0              48.0  ...               20.0   \n",
       "28              74.0              50.0  ...               20.0   \n",
       "29              47.0              33.0  ...               13.0   \n",
       "30              57.0              38.0  ...               16.0   \n",
       "\n",
       "    sales_42_forecast  sales_43_forecast  sales_44_forecast  \\\n",
       "0                33.0               48.0               26.0   \n",
       "1                21.0               31.0               16.0   \n",
       "2                25.0               36.0               20.0   \n",
       "3                25.0               37.0               19.0   \n",
       "4                27.0               39.0               22.0   \n",
       "5                29.0               42.0               23.0   \n",
       "6                31.0               45.0               25.0   \n",
       "7                34.0               48.0               26.0   \n",
       "8                22.0               31.0               16.0   \n",
       "9                26.0               35.0               20.0   \n",
       "10               26.0               36.0               19.0   \n",
       "11               28.0               38.0               21.0   \n",
       "12               30.0               41.0               23.0   \n",
       "13               32.0               44.0               24.0   \n",
       "14               35.0               47.0               26.0   \n",
       "15               23.0               30.0               16.0   \n",
       "16               26.0               34.0               20.0   \n",
       "17               27.0               36.0               19.0   \n",
       "18               29.0               38.0               21.0   \n",
       "19               31.0               41.0               23.0   \n",
       "20               32.0               44.0               25.0   \n",
       "21               35.0               47.0               26.0   \n",
       "22               23.0               30.0               16.0   \n",
       "23               26.0               35.0               20.0   \n",
       "24               27.0               36.0               19.0   \n",
       "25               29.0               38.0               22.0   \n",
       "26               31.0               42.0               23.0   \n",
       "27               33.0               45.0               25.0   \n",
       "28               35.0               48.0               27.0   \n",
       "29               23.0               31.0               17.0   \n",
       "30               27.0               36.0               21.0   \n",
       "\n",
       "    sales_45_forecast  sales_46_forecast  sales_47_forecast  \\\n",
       "0                76.0               56.0               20.0   \n",
       "1                47.0               35.0               13.0   \n",
       "2                57.0               41.0               16.0   \n",
       "3                57.0               42.0               16.0   \n",
       "4                61.0               46.0               17.0   \n",
       "5                66.0               49.0               18.0   \n",
       "6                69.0               51.0               19.0   \n",
       "7                77.0               56.0               20.0   \n",
       "8                47.0               35.0               13.0   \n",
       "9                57.0               42.0               15.0   \n",
       "10               57.0               42.0               16.0   \n",
       "11               61.0               46.0               17.0   \n",
       "12               66.0               49.0               18.0   \n",
       "13               69.0               52.0               19.0   \n",
       "14               77.0               56.0               20.0   \n",
       "15               47.0               36.0               13.0   \n",
       "16               57.0               42.0               16.0   \n",
       "17               57.0               43.0               16.0   \n",
       "18               61.0               47.0               17.0   \n",
       "19               66.0               50.0               18.0   \n",
       "20               70.0               53.0               20.0   \n",
       "21               77.0               57.0               21.0   \n",
       "22               48.0               36.0               13.0   \n",
       "23               58.0               43.0               16.0   \n",
       "24               58.0               44.0               16.0   \n",
       "25               61.0               47.0               18.0   \n",
       "26               67.0               51.0               18.0   \n",
       "27               70.0               53.0               20.0   \n",
       "28               78.0               58.0               21.0   \n",
       "29               49.0               37.0               14.0   \n",
       "30               59.0               43.0               17.0   \n",
       "\n",
       "    sales_48_forecast  sales_49_forecast  sales_50_forecast  \n",
       "0                48.0               27.0               61.0  \n",
       "1                30.0               17.0               38.0  \n",
       "2                36.0               20.0               46.0  \n",
       "3                36.0               20.0               47.0  \n",
       "4                39.0               23.0               50.0  \n",
       "5                42.0               23.0               53.0  \n",
       "6                45.0               25.0               58.0  \n",
       "7                48.0               27.0               61.0  \n",
       "8                30.0               17.0               39.0  \n",
       "9                36.0               20.0               46.0  \n",
       "10               36.0               20.0               47.0  \n",
       "11               39.0               23.0               50.0  \n",
       "12               43.0               23.0               53.0  \n",
       "13               45.0               25.0               58.0  \n",
       "14               49.0               27.0               61.0  \n",
       "15               31.0               17.0               39.0  \n",
       "16               37.0               20.0               46.0  \n",
       "17               37.0               20.0               48.0  \n",
       "18               40.0               23.0               50.0  \n",
       "19               43.0               23.0               54.0  \n",
       "20               46.0               25.0               59.0  \n",
       "21               50.0               28.0               62.0  \n",
       "22               31.0               17.0               39.0  \n",
       "23               37.0               21.0               47.0  \n",
       "24               37.0               20.0               48.0  \n",
       "25               40.0               23.0               51.0  \n",
       "26               44.0               24.0               55.0  \n",
       "27               46.0               26.0               60.0  \n",
       "28               50.0               28.0               63.0  \n",
       "29               32.0               18.0               40.0  \n",
       "30               38.0               21.0               48.0  \n",
       "\n",
       "[31 rows x 51 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_data() # no updated ornew data ie 1st process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d70b6c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T09:03:23.993578Z",
     "start_time": "2023-02-28T09:03:23.965006Z"
    }
   },
   "outputs": [],
   "source": [
    "new_path = r\"D:\\MLOPs POC\\python_files\\samp_data\\test\\next_month_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24de84d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T09:03:29.927990Z",
     "start_time": "2023-02-28T09:03:29.914220Z"
    }
   },
   "outputs": [],
   "source": [
    "pa = r\"D:\\MLOPs POC\\python_files\\prepros_sales_data\\updated_sales_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73abe3fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T09:04:00.533192Z",
     "start_time": "2023-02-28T09:04:00.512257Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6b9e1e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T09:04:29.676253Z",
     "start_time": "2023-02-28T09:04:29.616992Z"
    }
   },
   "outputs": [],
   "source": [
    "a1 = pd.read_csv(new_path)\n",
    "a2 = pd.read_csv(pa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c73f3a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T09:06:50.314009Z",
     "start_time": "2023-02-28T09:06:50.303813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.iloc[-1, 0] == a2.iloc[-1, 0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1734b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T09:06:39.129822Z",
     "start_time": "2023-02-28T09:06:39.119274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-01-31 '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.iloc[-1, 0][:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c40af7d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T09:14:07.044789Z",
     "start_time": "2023-02-28T09:14:07.017928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1550 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  store  item  sales\n",
       "0     2017-01-01      1     1     19\n",
       "899   2017-01-01      1    30     27\n",
       "1519  2017-01-01      1    50     49\n",
       "961   2017-01-01      1    32     32\n",
       "155   2017-01-01      1     6     52\n",
       "...          ...    ...   ...    ...\n",
       "867   2017-01-31      1    28     74\n",
       "836   2017-01-31      1    27     18\n",
       "805   2017-01-31      1    26     24\n",
       "1487  2017-01-31      1    48     34\n",
       "1549  2017-01-31      1    50     54\n",
       "\n",
       "[1550 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.sort_values(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75b81962",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T09:14:56.432001Z",
     "start_time": "2023-02-28T09:14:56.424003Z"
    }
   },
   "outputs": [],
   "source": [
    "aa = a1.groupby(\"item\").get_group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9f7c842",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T09:14:59.556094Z",
     "start_time": "2023-02-28T09:14:59.530384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-01-13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-01-17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-01-18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  store  item  sales\n",
       "0   2017-01-01      1     1     19\n",
       "1   2017-01-02      1     1     15\n",
       "2   2017-01-03      1     1     10\n",
       "3   2017-01-04      1     1     16\n",
       "4   2017-01-05      1     1     14\n",
       "5   2017-01-06      1     1     24\n",
       "6   2017-01-07      1     1     14\n",
       "7   2017-01-08      1     1     20\n",
       "8   2017-01-09      1     1     18\n",
       "9   2017-01-10      1     1     11\n",
       "10  2017-01-11      1     1     14\n",
       "11  2017-01-12      1     1     17\n",
       "12  2017-01-13      1     1      7\n",
       "13  2017-01-14      1     1     16\n",
       "14  2017-01-15      1     1     29\n",
       "15  2017-01-16      1     1     15\n",
       "16  2017-01-17      1     1     14\n",
       "17  2017-01-18      1     1     10\n",
       "18  2017-01-19      1     1     16\n",
       "19  2017-01-20      1     1     22\n",
       "20  2017-01-21      1     1     13\n",
       "21  2017-01-22      1     1     21\n",
       "22  2017-01-23      1     1      9\n",
       "23  2017-01-24      1     1     18\n",
       "24  2017-01-25      1     1     14\n",
       "25  2017-01-26      1     1     13\n",
       "26  2017-01-27      1     1     10\n",
       "27  2017-01-28      1     1     16\n",
       "28  2017-01-29      1     1     24\n",
       "29  2017-01-30      1     1      9\n",
       "30  2017-01-31      1     1     17"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b811d6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
